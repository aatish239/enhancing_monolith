{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dac78eb-5150-4bc3-ac8d-d1f0f6127d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score, accuracy_score,r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0026ab4-e05e-413b-a762-c0671e2c5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_df = pd.read_csv('processed_data/movies.csv')\n",
    "# users_df = pd.read_csv('processed_data/users_data_bert_embeddings.csv')\n",
    "\n",
    "# use this for now ..\n",
    "movies_df = pd.read_csv('backup_data/sample_data_for_model_training/sample_movies.csv')\n",
    "users_df = pd.read_csv('backup_data/sample_data_for_model_training/training_users_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1d2888-480b-4d50-83bd-73f0721370b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0     tconst  averageRating  numVotes  \\\n",
      "0             0             0         447  tt0000682            6.9      2982   \n",
      "1             1             1         448  tt0000683            5.6        97   \n",
      "2             2             2         449  tt0000684            5.0       140   \n",
      "3             3             3         458  tt0000700            5.0        83   \n",
      "4             4             4         460  tt0000706            5.2        33   \n",
      "\n",
      "   directors                         writers titleType  \\\n",
      "0  nm0169871                              \\N     short   \n",
      "1  nm0000428                       nm0000428     short   \n",
      "2  nm0000428                       nm0000428     short   \n",
      "3  nm0567363                              \\N     short   \n",
      "4  nm0000428  nm0000428,nm13388805,nm0786076     short   \n",
      "\n",
      "              primaryTitle            originalTitle  isAdult  startYear  \\\n",
      "0                A Fantasy            Fantasmagorie        0       1908   \n",
      "1           The Fatal Hour           The Fatal Hour        0       1908   \n",
      "2  Father Gets in the Game  Father Gets in the Game        0       1908   \n",
      "3      Her First Adventure      Her First Adventure        0       1908   \n",
      "4   Ingomar, the Barbarian   Ingomar, the Barbarian        0       1908   \n",
      "\n",
      "  endYear runtimeMinutes     genre1   genre2  genre3  \n",
      "0      \\N              2  Animation   Comedy  Family  \n",
      "1      \\N             14      Crime    Short     NaN  \n",
      "2      \\N             10     Comedy    Short     NaN  \n",
      "3      \\N              6      Drama    Short     NaN  \n",
      "4      \\N             13      Drama  Romance   Short      Unnamed: 0      user_id                                          movie_ids  \\\n",
      "0       20572    ur2022517  ['tt0024727', 'tt0035190', 'tt0042285', 'tt005...   \n",
      "1       19057  ur186072342  ['tt0015384', 'tt0019422', 'tt0029583', 'tt003...   \n",
      "2       35403    ur6261199                         ['tt0056285', 'tt0064188']   \n",
      "3        4831    ur0518971                         ['tt0054013', 'tt0054903']   \n",
      "4       11507  ur120947285  ['tt0024816', 'tt0024865', 'tt0026104', 'tt002...   \n",
      "\n",
      "                                        user_ratings  \\\n",
      "0  [0.6666666666666665, 0.2222222222222222, 0.666...   \n",
      "1  [0.0, 0.8888888888888888, 0.6666666666666665, ...   \n",
      "2           [0.7777777777777777, 0.6666666666666665]   \n",
      "3           [0.6666666666666665, 0.1111111111111111]   \n",
      "4  [0.6666666666666665, 1.0, 0.7777777777777777, ...   \n",
      "\n",
      "                                        user_reviews  \n",
      "0  tensor([ 1.0843e-01, -3.1500e-01, -3.4225e-01,...  \n",
      "1  tensor([ 2.6374e-01, -7.0189e-02,  1.7799e-01,...  \n",
      "2  tensor([ 1.4641e-01,  2.3382e-01, -2.9580e-01,...  \n",
      "3  tensor([ 1.3101e-02, -2.3237e-01,  5.5675e-01,...  \n",
      "4  tensor([-4.8468e-01, -3.6650e-01, -1.9936e-01,...   (31401, 18) (28739, 5)\n"
     ]
    }
   ],
   "source": [
    "movies_df_head = movies_df.head()\n",
    "users_df_head = users_df.head()\n",
    "\n",
    "movies_df_shape = movies_df.shape\n",
    "users_df_shape = users_df.shape\n",
    "\n",
    "print(movies_df_head, users_df_head, movies_df_shape, users_df_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00eda39-1da6-48ab-b24c-22ebadbfddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string representations of lists to actual lists in users_df\n",
    "users_df['movie_ids'] = users_df['movie_ids'].apply(ast.literal_eval)\n",
    "users_df['user_ratings'] = users_df['user_ratings'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c7ea02-fb5a-4c36-9869-567ffad94b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      user_id                                          movie_ids  \\\n",
      "0       20572    ur2022517  [tt0024727, tt0035190, tt0042285, tt0051134, t...   \n",
      "1       19057  ur186072342  [tt0015384, tt0019422, tt0029583, tt0032910, t...   \n",
      "2       35403    ur6261199                             [tt0056285, tt0064188]   \n",
      "3        4831    ur0518971                             [tt0054013, tt0054903]   \n",
      "4       11507  ur120947285  [tt0024816, tt0024865, tt0026104, tt0026121, t...   \n",
      "\n",
      "                                        user_ratings  \\\n",
      "0  [0.6666666666666665, 0.2222222222222222, 0.666...   \n",
      "1  [0.0, 0.8888888888888888, 0.6666666666666665, ...   \n",
      "2           [0.7777777777777777, 0.6666666666666665]   \n",
      "3           [0.6666666666666665, 0.1111111111111111]   \n",
      "4  [0.6666666666666665, 1.0, 0.7777777777777777, ...   \n",
      "\n",
      "                                        user_reviews  \n",
      "0  [0.10843, -0.315, -0.34225, 0.10103, 0.37387, ...  \n",
      "1  [0.26374, -0.070189, 0.17799, 0.18658, 0.42948...  \n",
      "2  [0.14641, 0.23382, -0.2958, -0.32118, 0.32941,...  \n",
      "3  [0.013101, -0.23237, 0.55675, 0.31472, 0.36427...  \n",
      "4  [-0.48468, -0.3665, -0.19936, 0.077204, 0.0884...   (28739, 5)\n"
     ]
    }
   ],
   "source": [
    "# For 'user_reviews', extract the tensor values\n",
    "def parse_tensor(tensor_str):\n",
    "    # Remove 'tensor([' and '])' and split by comma\n",
    "    values = tensor_str.replace('tensor([', '').replace('])', '').strip()\n",
    "    return [float(x) for x in values.split(',') if x.strip()]\n",
    "\n",
    "users_df['user_reviews'] = users_df['user_reviews'].apply(parse_tensor)\n",
    "\n",
    "# Check the processed data\n",
    "print(users_df.head(), users_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06398cf9-6b52-4009-9388-357543001d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      user_id                                          movie_ids  \\\n",
      "1       19057  ur186072342  [tt0015384, tt0019422, tt0029583, tt0032910, t...   \n",
      "2       35403    ur6261199                             [tt0056285, tt0064188]   \n",
      "3        4831    ur0518971                             [tt0054013, tt0054903]   \n",
      "4       11507  ur120947285  [tt0024816, tt0024865, tt0026104, tt0026121, t...   \n",
      "5         142    ur0017155                             [tt0031657, tt0066952]   \n",
      "\n",
      "                                        user_ratings  \\\n",
      "1  [0.0, 0.8888888888888888, 0.6666666666666665, ...   \n",
      "2           [0.7777777777777777, 0.6666666666666665]   \n",
      "3           [0.6666666666666665, 0.1111111111111111]   \n",
      "4  [0.6666666666666665, 1.0, 0.7777777777777777, ...   \n",
      "5           [0.5555555555555556, 0.6666666666666665]   \n",
      "\n",
      "                                        user_reviews  \n",
      "1  [[0.26374, -0.070189, 0.17799, 0.18658, 0.4294...  \n",
      "2  [[0.14641, 0.23382, -0.2958, -0.32118, 0.32941...  \n",
      "3  [[0.013101, -0.23237, 0.55675, 0.31472, 0.3642...  \n",
      "4  [[-0.48468, -0.3665, -0.19936, 0.077204, 0.088...  \n",
      "5  [[0.162, -0.43063, -0.21882, 0.35712, 0.37678,...   (26577, 5)\n"
     ]
    }
   ],
   "source": [
    "def split_reviews(row):\n",
    "    num_movies = len(row['movie_ids'])\n",
    "    reviews = row['user_reviews']\n",
    "\n",
    "    if len(reviews) % num_movies == 0:\n",
    "        split_size = len(reviews) // num_movies\n",
    "        return [reviews[i * split_size: (i + 1) * split_size] for i in range(num_movies)]\n",
    "    else:\n",
    "        return None  # Indicates problematic row\n",
    "\n",
    "# Apply the function\n",
    "users_df['split_reviews'] = users_df.apply(split_reviews, axis=1)\n",
    "\n",
    "# Identify rows that couldn't be fixed\n",
    "unfixable_rows = users_df[users_df['split_reviews'].isnull()]\n",
    "\n",
    "# Remove unfixable rows and update user_reviews with split_reviews\n",
    "users_df = users_df[users_df['split_reviews'].notnull()]\n",
    "users_df['user_reviews'] = users_df['split_reviews']\n",
    "\n",
    "# Drop the temporary column\n",
    "users_df = users_df.drop(columns=['split_reviews'])\n",
    "\n",
    "# Check the cleaned data\n",
    "print(users_df.head(), users_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93fbd9d6-caf7-4f0e-94dd-8c0269e44580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the user dataframe to have one row per movie rating and review\n",
    "users_exploded = users_df.explode(['movie_ids', 'user_ratings', 'user_reviews'])\n",
    "\n",
    "# Merge with the movies dataset on movie_ids (tconst in movies_df)\n",
    "merged_df = pd.merge(users_exploded, movies_df, left_on='movie_ids', right_on='tconst', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af7f1e3a-b808-46d3-81b9-252c6d9c3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0_x      user_id  movie_ids user_ratings  \\\n",
      "0         19057  ur186072342  tt0015384          0.0   \n",
      "1         19057  ur186072342  tt0019422     0.888889   \n",
      "2         19057  ur186072342  tt0029583     0.666667   \n",
      "3         19057  ur186072342  tt0032910          1.0   \n",
      "4         19057  ur186072342  tt0040580     0.555556   \n",
      "\n",
      "                                        user_reviews  Unnamed: 0.2  \\\n",
      "0  [0.26374, -0.070189, 0.17799, 0.18658, 0.42948...          1961   \n",
      "1  [-0.15262, 0.20243, 0.73813, 0.19402, -0.02785...          2828   \n",
      "2  [-0.01072, -0.37331, 0.16924, 0.15325, -0.1456...          8268   \n",
      "3  [-0.043972, 0.28374, 0.13589, 0.57326, 0.14113...         10200   \n",
      "4  [0.54501, 0.83112, 0.45529, 0.43781, -0.010706...         14792   \n",
      "\n",
      "   Unnamed: 0.1  Unnamed: 0_y     tconst  averageRating  ...  startYear  \\\n",
      "0          2021          4726  tt0015384            6.0  ...       1924   \n",
      "1          2931          6563  tt0019422            7.5  ...       1928   \n",
      "2          8541         14114  tt0029583            7.6  ...       1937   \n",
      "3         10519         16849  tt0032910            7.5  ...       1940   \n",
      "4         15276         23279  tt0040580            6.1  ...       1948   \n",
      "\n",
      "  endYear runtimeMinutes     genre1     genre2  genre3  \\\n",
      "0      \\N              7  Animation      Music   Short   \n",
      "1      \\N              8  Animation     Comedy  Family   \n",
      "2      \\N             83  Adventure  Animation  Family   \n",
      "3      \\N             88  Adventure  Animation  Comedy   \n",
      "4      \\N             75  Animation     Comedy  Family   \n",
      "\n",
      "                           genres  \\\n",
      "0       [Animation, Music, Short]   \n",
      "1     [Animation, Comedy, Family]   \n",
      "2  [Adventure, Animation, Family]   \n",
      "3  [Adventure, Animation, Comedy]   \n",
      "4     [Animation, Comedy, Family]   \n",
      "\n",
      "                                      directors_list  \\\n",
      "0                                        [nm0250873]   \n",
      "1                             [nm0412650, nm0000370]   \n",
      "2  [nm0183183, nm0359457, nm0414144, nm0604392, n...   \n",
      "3  [nm0272568, nm0373429, nm0414144, nm0455741, n...   \n",
      "4       [nm0314671, nm0414144, nm0455741, nm0527217]   \n",
      "\n",
      "                                        writers_list  \\\n",
      "0                                               [\\N]   \n",
      "1                             [nm0000370, nm0412650]   \n",
      "2  [nm0342278, nm0342303, nm0780799, nm0187232, n...   \n",
      "3  [nm0172830, nm0780799, nm0257481, nm0810324, n...   \n",
      "4  [nm0382548, nm0672093, nm0716206, nm0109205, n...   \n",
      "\n",
      "                                 user_reviews_padded  \n",
      "0  [0.26374, -0.070189, 0.17799, 0.18658, 0.42948...  \n",
      "1  [-0.15262, 0.20243, 0.73813, 0.19402, -0.02785...  \n",
      "2  [-0.01072, -0.37331, 0.16924, 0.15325, -0.1456...  \n",
      "3  [-0.043972, 0.28374, 0.13589, 0.57326, 0.14113...  \n",
      "4  [0.54501, 0.83112, 0.45529, 0.43781, -0.010706...  \n",
      "\n",
      "[5 rows x 27 columns] (41360, 27)\n"
     ]
    }
   ],
   "source": [
    "# Function to pad tensors to length 768\n",
    "def pad_tensor(tensor, target_length=768):\n",
    "    if len(tensor) < target_length:\n",
    "        return np.pad(tensor, (0, target_length - len(tensor)), 'constant')\n",
    "    return tensor[:target_length]  # Truncate if longer than 768\n",
    "\n",
    "\n",
    "# Combine genre columns into a list for one-hot encoding\n",
    "merged_df['genres'] = merged_df[['genre1', 'genre2', 'genre3']].values.tolist()\n",
    "merged_df['genres'] = merged_df['genres'].apply(lambda x: [g for g in x if pd.notnull(g)])\n",
    "\n",
    "# One-hot encode genres\n",
    "mlb_genres = MultiLabelBinarizer()\n",
    "genre_encoded = mlb_genres.fit_transform(merged_df['genres'])\n",
    "\n",
    "# Process directors and writers (split by comma and one-hot encode)\n",
    "merged_df['directors_list'] = merged_df['directors'].apply(lambda x: x.split(',') if pd.notnull(x) else [])\n",
    "merged_df['writers_list'] = merged_df['writers'].apply(lambda x: x.split(',') if pd.notnull(x) else [])\n",
    "\n",
    "mlb_directors = MultiLabelBinarizer()\n",
    "mlb_writers = MultiLabelBinarizer()\n",
    "\n",
    "directors_encoded = mlb_directors.fit_transform(merged_df['directors_list'])\n",
    "writers_encoded = mlb_writers.fit_transform(merged_df['writers_list'])\n",
    "# Apply padding\n",
    "merged_df['user_reviews_padded'] = merged_df['user_reviews'].apply(pad_tensor)\n",
    "# merged_df.to_csv('processed_data/merged_dataset.csv')\n",
    "merged_df.to_csv('processed_data/merged_dataset_sample_training.csv')\n",
    "print(merged_df.head(), merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be18ff29-e91a-48f3-bf3d-6ed795858e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41360, 25641) (41360,)\n",
      "   Unnamed: 0_x      user_id  movie_ids user_ratings  \\\n",
      "0         19057  ur186072342  tt0015384          0.0   \n",
      "1         19057  ur186072342  tt0019422     0.888889   \n",
      "2         19057  ur186072342  tt0029583     0.666667   \n",
      "3         19057  ur186072342  tt0032910          1.0   \n",
      "4         19057  ur186072342  tt0040580     0.555556   \n",
      "\n",
      "                                        user_reviews  Unnamed: 0.2  \\\n",
      "0  [0.26374, -0.070189, 0.17799, 0.18658, 0.42948...          1961   \n",
      "1  [-0.15262, 0.20243, 0.73813, 0.19402, -0.02785...          2828   \n",
      "2  [-0.01072, -0.37331, 0.16924, 0.15325, -0.1456...          8268   \n",
      "3  [-0.043972, 0.28374, 0.13589, 0.57326, 0.14113...         10200   \n",
      "4  [0.54501, 0.83112, 0.45529, 0.43781, -0.010706...         14792   \n",
      "\n",
      "   Unnamed: 0.1  Unnamed: 0_y     tconst  averageRating  ...  startYear  \\\n",
      "0          2021          4726  tt0015384            6.0  ...       1924   \n",
      "1          2931          6563  tt0019422            7.5  ...       1928   \n",
      "2          8541         14114  tt0029583            7.6  ...       1937   \n",
      "3         10519         16849  tt0032910            7.5  ...       1940   \n",
      "4         15276         23279  tt0040580            6.1  ...       1948   \n",
      "\n",
      "  endYear runtimeMinutes     genre1     genre2  genre3  \\\n",
      "0      \\N              7  Animation      Music   Short   \n",
      "1      \\N              8  Animation     Comedy  Family   \n",
      "2      \\N             83  Adventure  Animation  Family   \n",
      "3      \\N             88  Adventure  Animation  Comedy   \n",
      "4      \\N             75  Animation     Comedy  Family   \n",
      "\n",
      "                           genres  \\\n",
      "0       [Animation, Music, Short]   \n",
      "1     [Animation, Comedy, Family]   \n",
      "2  [Adventure, Animation, Family]   \n",
      "3  [Adventure, Animation, Comedy]   \n",
      "4     [Animation, Comedy, Family]   \n",
      "\n",
      "                                      directors_list  \\\n",
      "0                                        [nm0250873]   \n",
      "1                             [nm0412650, nm0000370]   \n",
      "2  [nm0183183, nm0359457, nm0414144, nm0604392, n...   \n",
      "3  [nm0272568, nm0373429, nm0414144, nm0455741, n...   \n",
      "4       [nm0314671, nm0414144, nm0455741, nm0527217]   \n",
      "\n",
      "                                        writers_list  \\\n",
      "0                                               [\\N]   \n",
      "1                             [nm0000370, nm0412650]   \n",
      "2  [nm0342278, nm0342303, nm0780799, nm0187232, n...   \n",
      "3  [nm0172830, nm0780799, nm0257481, nm0810324, n...   \n",
      "4  [nm0382548, nm0672093, nm0716206, nm0109205, n...   \n",
      "\n",
      "                                 user_reviews_padded  \n",
      "0  [0.26374, -0.070189, 0.17799, 0.18658, 0.42948...  \n",
      "1  [-0.15262, 0.20243, 0.73813, 0.19402, -0.02785...  \n",
      "2  [-0.01072, -0.37331, 0.16924, 0.15325, -0.1456...  \n",
      "3  [-0.043972, 0.28374, 0.13589, 0.57326, 0.14113...  \n",
      "4  [0.54501, 0.83112, 0.45529, 0.43781, -0.010706...  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Index(['Unnamed: 0_x', 'user_id', 'movie_ids', 'user_ratings', 'user_reviews',\n",
      "       'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0_y', 'tconst',\n",
      "       'averageRating', 'numVotes', 'directors', 'writers', 'titleType',\n",
      "       'primaryTitle', 'originalTitle', 'isAdult', 'startYear', 'endYear',\n",
      "       'runtimeMinutes', 'genre1', 'genre2', 'genre3', 'genres',\n",
      "       'directors_list', 'writers_list', 'user_reviews_padded'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.32 GiB for an array with shape (33088, 25641) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m---> 16\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2683\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m-> 2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2684\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2685\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2686\u001b[0m     )\n\u001b[0;32m   2687\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2685\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2684\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2685\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2686\u001b[0m     )\n\u001b[0;32m   2687\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:411\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _polars_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:208\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    207\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array[key, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.32 GiB for an array with shape (33088, 25641) and data type float64"
     ]
    }
   ],
   "source": [
    "# Concatenate all features\n",
    "X = np.concatenate([\n",
    "    np.vstack(merged_df['user_reviews_padded'].values),  # Padded user review embeddings\n",
    "    genre_encoded,\n",
    "    directors_encoded,\n",
    "    writers_encoded\n",
    "], axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = merged_df['user_ratings'].astype(float).values\n",
    "\n",
    "# Check the shape of the feature matrix and target vector\n",
    "print(X.shape, y.shape)\n",
    "print(merged_df.head())\n",
    "print(merged_df.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d248c-85a4-48ab-abf1-9df7866cfcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=4, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a317be0-1dd7-46d5-9ea5-7189fd06314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original model\n",
    "os.makedirs('model_directory', exist_ok=True)\n",
    "model.save('model_directory/original_model.keras')\n",
    "\n",
    "# Convert to a lightweight TensorFlow Lite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the lightweight model\n",
    "with open('model_directory/lightweight_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfc596-594b-4137-bc01-c0b08ca49d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Precision@K, Recall@K, Accuracy@K\n",
    "K = 5\n",
    "sorted_indices = np.argsort(y_pred.flatten())[::-1][:K]\n",
    "\n",
    "y_true_top_k = (y_test[sorted_indices] >= 4).astype(int)  # Assuming rating >=4 is positive\n",
    "y_pred_top_k = (y_pred.flatten()[sorted_indices] >= 4).astype(int)\n",
    "\n",
    "precision_at_k = precision_score(y_true_top_k, y_pred_top_k, zero_division=0)\n",
    "recall_at_k = recall_score(y_true_top_k, y_pred_top_k, zero_division=0)\n",
    "accuracy_at_k = accuracy_score(y_true_top_k, y_pred_top_k)\n",
    "\n",
    "print(f'Loss: {loss}, MAE: {mae}, R2: {r2}, rmse: {rmse}')\n",
    "print(f'Precision@{K}: {precision_at_k}, Recall@{K}: {recall_at_k}, Accuracy@{K}: {accuracy_at_k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea651d-f6e0-4363-80b6-45a6fc22d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation Function\n",
    "def recommend_movies(fav_genres, fav_directors, fav_writers, top_n=5):\n",
    "    genre_vector = mlb_genres.transform([fav_genres])\n",
    "    director_vector = mlb_directors.transform([fav_directors])\n",
    "    writer_vector = mlb_writers.transform([fav_writers])\n",
    "\n",
    "    recommendations = []\n",
    "    for index, row in merged_df.iterrows():\n",
    "        features = np.concatenate([\n",
    "            row['user_reviews_padded'],\n",
    "            genre_vector[0],\n",
    "            director_vector[0],\n",
    "            writer_vector[0]\n",
    "        ]).reshape(1, -1)\n",
    "        predicted_rating = model.predict(features)[0][0]\n",
    "        recommendations.append((row['primaryTitle'], predicted_rating))\n",
    "\n",
    "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe4c73-5fbf-48cc-899a-2d12e4c6c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend movies along with user rating for a cold start user  based on genres, directors and writers.\n",
    "# print the average user rating by that user.\n",
    "# Example usage\n",
    "fav_genres = ['Comedy', 'Drama', 'Action']\n",
    "fav_directors = ['nm0412650', 'nm0000370']\n",
    "fav_writers = ['nm0522871', 'nm0250873']\n",
    "\n",
    "recommendations = recommend_movies(fav_genres, fav_directors, fav_writers)\n",
    "for movie, score in recommendations:\n",
    "    print(f\"{movie}: {score}\")\n",
    "ratings = [rating for _, rating in recommendations]\n",
    "print(np.mean(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a2515-66f7-45b8-a9c9-c1ff554bbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_users(movie_genres, movie_directors, movie_writers, top_n=5):\n",
    "    genre_vector = mlb_genres.transform([movie_genres])\n",
    "    director_vector = mlb_directors.transform([movie_directors])\n",
    "    writer_vector = mlb_writers.transform([movie_writers])\n",
    "\n",
    "    recommendations = []\n",
    "    for index, row in merged_df.iterrows():\n",
    "        features = np.concatenate([\n",
    "            row['user_reviews_padded'],\n",
    "            genre_vector[0],\n",
    "            director_vector[0],\n",
    "            writer_vector[0]\n",
    "        ]).reshape(1, -1)\n",
    "        predicted_rating = model.predict(features)[0][0]\n",
    "        recommendations.append((row['user_id'], predicted_rating))\n",
    "\n",
    "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)\n",
    "    return recommendations[:top_n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e95484-d32f-4ff3-88d6-838beb56e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend users and user rating for the movie where the movie genre, writers and directors are provided.\n",
    "movie_genres = ['Action', 'Thriller']\n",
    "movie_directors = ['nm0883213']\n",
    "movie_writers = ['nm0522871']\n",
    "\n",
    "user_recommendations = recommend_users(movie_genres, movie_directors, movie_writers)\n",
    "for user, score in user_recommendations:\n",
    "    print(f\"User {user}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b9cf0-9544-4c18-acaf-34f393ed1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend Movies for a Test User\n",
    "def evaluate_recommendations_for_test_user():\n",
    "    # Select a user from the test data\n",
    "    test_user_index = 0\n",
    "    test_user_features = X_test[test_user_index]\n",
    "    test_user_actual_rating = y_test[test_user_index]\n",
    "\n",
    "    # Identify favorite genres, directors, and writers from the merged dataset\n",
    "    test_user_data = merged_df.iloc[test_user_index]\n",
    "    fav_genres = test_user_data['genres']\n",
    "    fav_directors = test_user_data['directors_list']\n",
    "    fav_writers = test_user_data['writers_list']\n",
    "\n",
    "    # Get recommendations\n",
    "    recommendations = recommend_movies(fav_genres, fav_directors, fav_writers)\n",
    "\n",
    "    # Evaluate\n",
    "    print(f\"Actual Rating: {test_user_actual_rating}\")\n",
    "    for movie, predicted_rating in recommendations:\n",
    "        print(f\"Recommended Movie: {movie}, Predicted Rating: {predicted_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce11db6-926b-473d-bbd4-0cf43ae0d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_recommendations_for_test_user()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14447b4b-e17a-424f-beac-e722f2438be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lightweight_models():\n",
    "    # Load the lightweight model for evaluation\n",
    "    interpreter = tf.lite.Interpreter(model_path='model_directory/lightweight_model.tflite')\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Function to predict using the lightweight model\n",
    "    def predict_with_tflite(input_data):\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n",
    "        interpreter.invoke()\n",
    "        return interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    # Evaluate both models\n",
    "    def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae = np.mean(np.abs(y_true - y_pred))\n",
    "        loss = mean_squared_error(y_true, y_pred)\n",
    "        # accuracy = accuracy_score(y_true.round(), y_pred.round())\n",
    "        # precision = precision_score(y_true.round(), y_pred.round(), average='weighted', zero_division=0)\n",
    "        # recall = recall_score(y_true.round(), y_pred.round(), average='weighted', zero_division=0)\n",
    "        # r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"{model_name} Evaluation:\\nRMSE: {rmse}, MAE: {mae}, Loss: {loss}\\n\")\n",
    "\n",
    "    # Original Model Evaluation\n",
    "    y_pred_original = model.predict(X_test)\n",
    "    evaluate_model(y_test, y_pred_original, model_name=\"Original Model\")\n",
    "\n",
    "    # Lightweight Model Evaluation\n",
    "    y_pred_tflite = np.array([predict_with_tflite(x.reshape(1, -1))[0][0] for x in X_test])\n",
    "    evaluate_model(y_test, y_pred_tflite, model_name=\"Lightweight Model\")\n",
    "    print(\"lightweight\" , os.stat('model_directory/lightweight_model.tflite').st_size)\n",
    "    print(\"Original\" , os.stat('model_directory/original_model.keras').st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a47d8-9f71-43cd-8a75-dabe040f7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_lightweight_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
