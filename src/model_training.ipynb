{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dac78eb-5150-4bc3-ac8d-d1f0f6127d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score, accuracy_score,r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0026ab4-e05e-413b-a762-c0671e2c5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_df = pd.read_csv('processed_data/movies.csv')\n",
    "# users_df = pd.read_csv('processed_data/users_data_bert_embeddings.csv')\n",
    "\n",
    "# use this for now ..\n",
    "movies_df = pd.read_csv('backup_data/sample_data_for_model_training/sample_movies.csv')\n",
    "users_df = pd.read_csv('backup_data/sample_data_for_model_training/training_users_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d2888-480b-4d50-83bd-73f0721370b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_head = movies_df.head()\n",
    "users_df_head = users_df.head()\n",
    "\n",
    "movies_df_shape = movies_df.shape\n",
    "users_df_shape = users_df.shape\n",
    "\n",
    "print(movies_df_head, users_df_head, movies_df_shape, users_df_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00eda39-1da6-48ab-b24c-22ebadbfddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string representations of lists to actual lists in users_df\n",
    "users_df['movie_ids'] = users_df['movie_ids'].apply(ast.literal_eval)\n",
    "users_df['user_ratings'] = users_df['user_ratings'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7ea02-fb5a-4c36-9869-567ffad94b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 'user_reviews', extract the tensor values\n",
    "def parse_tensor(tensor_str):\n",
    "    # Remove 'tensor([' and '])' and split by comma\n",
    "    values = tensor_str.replace('tensor([', '').replace('])', '').strip()\n",
    "    return [float(x) for x in values.split(',') if x.strip()]\n",
    "\n",
    "users_df['user_reviews'] = users_df['user_reviews'].apply(parse_tensor)\n",
    "\n",
    "# Check the processed data\n",
    "print(users_df.head(), users_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06398cf9-6b52-4009-9388-357543001d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_reviews(row):\n",
    "    num_movies = len(row['movie_ids'])\n",
    "    reviews = row['user_reviews']\n",
    "\n",
    "    if len(reviews) % num_movies == 0:\n",
    "        split_size = len(reviews) // num_movies\n",
    "        return [reviews[i * split_size: (i + 1) * split_size] for i in range(num_movies)]\n",
    "    else:\n",
    "        return None  # Indicates problematic row\n",
    "\n",
    "# Apply the function\n",
    "users_df['split_reviews'] = users_df.apply(split_reviews, axis=1)\n",
    "\n",
    "# Identify rows that couldn't be fixed\n",
    "unfixable_rows = users_df[users_df['split_reviews'].isnull()]\n",
    "\n",
    "# Remove unfixable rows and update user_reviews with split_reviews\n",
    "users_df = users_df[users_df['split_reviews'].notnull()]\n",
    "users_df['user_reviews'] = users_df['split_reviews']\n",
    "\n",
    "# Drop the temporary column\n",
    "users_df = users_df.drop(columns=['split_reviews'])\n",
    "\n",
    "# Check the cleaned data\n",
    "print(users_df.head(), users_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fbd9d6-caf7-4f0e-94dd-8c0269e44580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the user dataframe to have one row per movie rating and review\n",
    "users_exploded = users_df.explode(['movie_ids', 'user_ratings', 'user_reviews'])\n",
    "\n",
    "# Merge with the movies dataset on movie_ids (tconst in movies_df)\n",
    "merged_df = pd.merge(users_exploded, movies_df, left_on='movie_ids', right_on='tconst', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f1e3a-b808-46d3-81b9-252c6d9c3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pad tensors to length 768\n",
    "def pad_tensor(tensor, target_length=768):\n",
    "    if len(tensor) < target_length:\n",
    "        return np.pad(tensor, (0, target_length - len(tensor)), 'constant')\n",
    "    return tensor[:target_length]  # Truncate if longer than 768\n",
    "\n",
    "\n",
    "# Combine genre columns into a list for one-hot encoding\n",
    "merged_df['genres'] = merged_df[['genre1', 'genre2', 'genre3']].values.tolist()\n",
    "merged_df['genres'] = merged_df['genres'].apply(lambda x: [g for g in x if pd.notnull(g)])\n",
    "\n",
    "# One-hot encode genres\n",
    "mlb_genres = MultiLabelBinarizer()\n",
    "genre_encoded = mlb_genres.fit_transform(merged_df['genres'])\n",
    "\n",
    "# Process directors and writers (split by comma and one-hot encode)\n",
    "merged_df['directors_list'] = merged_df['directors'].apply(lambda x: x.split(',') if pd.notnull(x) else [])\n",
    "merged_df['writers_list'] = merged_df['writers'].apply(lambda x: x.split(',') if pd.notnull(x) else [])\n",
    "\n",
    "mlb_directors = MultiLabelBinarizer()\n",
    "mlb_writers = MultiLabelBinarizer()\n",
    "\n",
    "directors_encoded = mlb_directors.fit_transform(merged_df['directors_list'])\n",
    "writers_encoded = mlb_writers.fit_transform(merged_df['writers_list'])\n",
    "# Apply padding\n",
    "merged_df['user_reviews_padded'] = merged_df['user_reviews'].apply(pad_tensor)\n",
    "merged_df.to_csv('processed_data/merged_dataset.csv')\n",
    "print(merged_df.head(), merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18ff29-e91a-48f3-bf3d-6ed795858e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all features\n",
    "X = np.concatenate([\n",
    "    np.vstack(merged_df['user_reviews_padded'].values),  # Padded user review embeddings\n",
    "    genre_encoded,\n",
    "    directors_encoded,\n",
    "    writers_encoded\n",
    "], axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = merged_df['user_ratings'].astype(float).values\n",
    "\n",
    "# Check the shape of the feature matrix and target vector\n",
    "print(X.shape, y.shape)\n",
    "print(merged_df.head())\n",
    "print(merged_df.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d248c-85a4-48ab-abf1-9df7866cfcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=4, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a317be0-1dd7-46d5-9ea5-7189fd06314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original model\n",
    "os.makedirs('model_directory', exist_ok=True)\n",
    "model.save('model_directory/original_model.keras')\n",
    "\n",
    "# Convert to a lightweight TensorFlow Lite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the lightweight model\n",
    "with open('model_directory/lightweight_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfc596-594b-4137-bc01-c0b08ca49d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Precision@K, Recall@K, Accuracy@K\n",
    "K = 5\n",
    "sorted_indices = np.argsort(y_pred.flatten())[::-1][:K]\n",
    "\n",
    "y_true_top_k = (y_test[sorted_indices] >= 4).astype(int)  # Assuming rating >=4 is positive\n",
    "y_pred_top_k = (y_pred.flatten()[sorted_indices] >= 4).astype(int)\n",
    "\n",
    "precision_at_k = precision_score(y_true_top_k, y_pred_top_k, zero_division=0)\n",
    "recall_at_k = recall_score(y_true_top_k, y_pred_top_k, zero_division=0)\n",
    "accuracy_at_k = accuracy_score(y_true_top_k, y_pred_top_k)\n",
    "\n",
    "print(f'Loss: {loss}, MAE: {mae}, R2: {r2}, rmse: {rmse}')\n",
    "print(f'Precision@{K}: {precision_at_k}, Recall@{K}: {recall_at_k}, Accuracy@{K}: {accuracy_at_k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea651d-f6e0-4363-80b6-45a6fc22d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation Function\n",
    "def recommend_movies(fav_genres, fav_directors, fav_writers, top_n=5):\n",
    "    genre_vector = mlb_genres.transform([fav_genres])\n",
    "    director_vector = mlb_directors.transform([fav_directors])\n",
    "    writer_vector = mlb_writers.transform([fav_writers])\n",
    "\n",
    "    recommendations = []\n",
    "    for index, row in merged_df.iterrows():\n",
    "        features = np.concatenate([\n",
    "            row['user_reviews_padded'],\n",
    "            genre_vector[0],\n",
    "            director_vector[0],\n",
    "            writer_vector[0]\n",
    "        ]).reshape(1, -1)\n",
    "        predicted_rating = model.predict(features)[0][0]\n",
    "        recommendations.append((row['primaryTitle'], predicted_rating))\n",
    "\n",
    "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe4c73-5fbf-48cc-899a-2d12e4c6c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend movies along with user rating for a cold start user  based on genres, directors and writers.\n",
    "# print the average user rating by that user.\n",
    "# Example usage\n",
    "fav_genres = ['Comedy', 'Drama', 'Action']\n",
    "fav_directors = ['nm0412650', 'nm0000370']\n",
    "fav_writers = ['nm0522871', 'nm0250873']\n",
    "\n",
    "recommendations = recommend_movies(fav_genres, fav_directors, fav_writers)\n",
    "for movie, score in recommendations:\n",
    "    print(f\"{movie}: {score}\")\n",
    "ratings = [rating for _, rating in recommendations]\n",
    "print(np.mean(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a2515-66f7-45b8-a9c9-c1ff554bbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_users(movie_genres, movie_directors, movie_writers, top_n=5):\n",
    "    genre_vector = mlb_genres.transform([movie_genres])\n",
    "    director_vector = mlb_directors.transform([movie_directors])\n",
    "    writer_vector = mlb_writers.transform([movie_writers])\n",
    "\n",
    "    recommendations = []\n",
    "    for index, row in merged_df.iterrows():\n",
    "        features = np.concatenate([\n",
    "            row['user_reviews_padded'],\n",
    "            genre_vector[0],\n",
    "            director_vector[0],\n",
    "            writer_vector[0]\n",
    "        ]).reshape(1, -1)\n",
    "        predicted_rating = model.predict(features)[0][0]\n",
    "        recommendations.append((row['user_id'], predicted_rating))\n",
    "\n",
    "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)\n",
    "    return recommendations[:top_n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e95484-d32f-4ff3-88d6-838beb56e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend users and user rating for the movie where the movie genre, writers and directors are provided.\n",
    "movie_genres = ['Action', 'Thriller']\n",
    "movie_directors = ['nm0883213']\n",
    "movie_writers = ['nm0522871']\n",
    "\n",
    "user_recommendations = recommend_users(movie_genres, movie_directors, movie_writers)\n",
    "for user, score in user_recommendations:\n",
    "    print(f\"User {user}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b9cf0-9544-4c18-acaf-34f393ed1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend Movies for a Test User\n",
    "def evaluate_recommendations_for_test_user():\n",
    "    # Select a user from the test data\n",
    "    test_user_index = 0\n",
    "    test_user_features = X_test[test_user_index]\n",
    "    test_user_actual_rating = y_test[test_user_index]\n",
    "\n",
    "    # Identify favorite genres, directors, and writers from the merged dataset\n",
    "    test_user_data = merged_df.iloc[test_user_index]\n",
    "    fav_genres = test_user_data['genres']\n",
    "    fav_directors = test_user_data['directors_list']\n",
    "    fav_writers = test_user_data['writers_list']\n",
    "\n",
    "    # Get recommendations\n",
    "    recommendations = recommend_movies(fav_genres, fav_directors, fav_writers)\n",
    "\n",
    "    # Evaluate\n",
    "    print(f\"Actual Rating: {test_user_actual_rating}\")\n",
    "    for movie, predicted_rating in recommendations:\n",
    "        print(f\"Recommended Movie: {movie}, Predicted Rating: {predicted_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce11db6-926b-473d-bbd4-0cf43ae0d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_recommendations_for_test_user()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14447b4b-e17a-424f-beac-e722f2438be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lightweight_models():\n",
    "    # Load the lightweight model for evaluation\n",
    "    interpreter = tf.lite.Interpreter(model_path='model_directory/lightweight_model.tflite')\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Function to predict using the lightweight model\n",
    "    def predict_with_tflite(input_data):\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n",
    "        interpreter.invoke()\n",
    "        return interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    # Evaluate both models\n",
    "    def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae = np.mean(np.abs(y_true - y_pred))\n",
    "        loss = mean_squared_error(y_true, y_pred)\n",
    "        # accuracy = accuracy_score(y_true.round(), y_pred.round())\n",
    "        # precision = precision_score(y_true.round(), y_pred.round(), average='weighted', zero_division=0)\n",
    "        # recall = recall_score(y_true.round(), y_pred.round(), average='weighted', zero_division=0)\n",
    "        # r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"{model_name} Evaluation:\\nRMSE: {rmse}, MAE: {mae}, Loss: {loss}\\n\")\n",
    "\n",
    "    # Original Model Evaluation\n",
    "    y_pred_original = model.predict(X_test)\n",
    "    evaluate_model(y_test, y_pred_original, model_name=\"Original Model\")\n",
    "\n",
    "    # Lightweight Model Evaluation\n",
    "    y_pred_tflite = np.array([predict_with_tflite(x.reshape(1, -1))[0][0] for x in X_test])\n",
    "    evaluate_model(y_test, y_pred_tflite, model_name=\"Lightweight Model\")\n",
    "    print(\"lightweight\" , os.stat('model_directory/lightweight_model.tflite').st_size)\n",
    "    print(\"Original\" , os.stat('model_directory/original_model.keras').st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a47d8-9f71-43cd-8a75-dabe040f7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_lightweight_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
