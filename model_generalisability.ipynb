{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import mean_squared_error, precision_score, recall_score, accuracy_score,r2_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
      ],
      "metadata": {
        "id": "aTi8jyBalToA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df_loc = r\"drive/MyDrive/MSUoA/goodreads/goodreads_users_data_bert_embeddings.csv\"\n",
        "merged_df = pd.read_csv(merged_df_loc, index_col=0)"
      ],
      "metadata": {
        "id": "bchrVUZXlahS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import ast\n",
        "import json\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler\n",
        "\n",
        "\n",
        "# Function to safely convert string lists to Python lists\n",
        "def safe_eval_list(x):\n",
        "    if isinstance(x, str):\n",
        "        return ast.literal_eval(x)\n",
        "    return x\n",
        "\n",
        "# Fill NaN and convert lists\n",
        "merged_df['genres'] = merged_df['genres'].fillna('[]').apply(safe_eval_list)\n",
        "\n",
        "# Convert tensor-based embeddings to numpy arrays\n",
        "def convert_tensor_to_array(x):\n",
        "    if isinstance(x, str) and x.startswith(\"tensor(\"):\n",
        "        try:\n",
        "            x = x.replace(\"tensor(\", \"\").rstrip(\")\")\n",
        "            return np.array(json.loads(x.replace(\"'\", \"\\\"\")))\n",
        "        except json.JSONDecodeError:\n",
        "            return np.zeros(embedding_dim)  # Fallback to zero vector\n",
        "    return np.array(x)\n",
        "\n",
        "merged_df['review_text'] = merged_df['review_text'].apply(convert_tensor_to_array)\n",
        "\n",
        "# Determine embedding dimension\n",
        "if not merged_df['review_text'].empty:\n",
        "    embedding_dim = len(merged_df['review_text'].iloc[0])\n",
        "else:\n",
        "    embedding_dim = 0  # Handle empty cases\n",
        "\n",
        "# Ensure embeddings are consistent\n",
        "merged_df['review_text'] = merged_df['review_text'].apply(\n",
        "    lambda x: x if len(x) == embedding_dim else np.zeros(embedding_dim)\n",
        ")\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "all_genres = set().union(*merged_df['genres'])\n",
        "\n",
        "mlb_genres = MultiLabelBinarizer().fit([list(all_genres)])\n",
        "genres_encoded = mlb_genres.transform(merged_df['genres'])\n",
        "\n",
        "# Normalize numerical features\n",
        "merged_df[['goodreads_rating', 'bbeVotes']] = merged_df[['goodreads_rating', 'bbeVotes']].fillna(0)\n",
        "scaler_numeric = MinMaxScaler()\n",
        "numeric_features = scaler_numeric.fit_transform(merged_df[['goodreads_rating', 'bbeVotes']])\n",
        "\n",
        "# Concatenate all features into X\n",
        "X_list = [\n",
        "    np.vstack(merged_df['review_text'].values) if embedding_dim > 0 else np.empty((len(merged_df), 0)),\n",
        "    numeric_features,\n",
        "    genres_encoded\n",
        "]\n",
        "\n",
        "X = np.concatenate(X_list, axis=1)\n",
        "\n",
        "# Define y (scaled user ratings)\n",
        "y = merged_df['user_rating'].values\n",
        "\n",
        "# Display processed X and y shapes\n",
        "X.shape, y.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4N7T7DnEMiZ",
        "outputId": "6df5ba31-0208-4cb3-bed2-1608065e78d5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 1528), (40000,))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Encode user IDs and book IDs (instead of movie IDs)\n",
        "user_encoder = LabelEncoder()\n",
        "book_encoder = LabelEncoder()\n",
        "\n",
        "merged_df['user_id_encoded'] = user_encoder.fit_transform(merged_df['user_id'])\n",
        "merged_df['book_id_encoded'] = book_encoder.fit_transform(merged_df['book_id'])\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "y_scaled = merged_df['user_rating'].values  # No need to scale user ratings\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, book_train, book_test = train_test_split(\n",
        "    X, y_scaled, merged_df['book_id_encoded'].values, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "# Check the shapes of training data\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"book_train shape:\", book_train.shape)\n",
        "\n",
        "# Book ID Input Layer\n",
        "book_input = Input(shape=(1,), name='book_input')\n",
        "book_embedding = Embedding(input_dim=len(book_encoder.classes_), output_dim=50, name='book_embedding')(book_input)\n",
        "book_vec = Flatten(name='book_flatten')(book_embedding)\n",
        "\n",
        "# Contextual Features Input Layer\n",
        "context_input = Input(shape=(X_train.shape[1],), name='context_input')\n",
        "\n",
        "# Concatenate book embedding with context input\n",
        "concat = Concatenate()([book_vec, context_input])\n",
        "\n",
        "# Dense Layers for cold-start recommendation\n",
        "x = Dense(512, activation='relu')(concat)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "output = Dense(1, activation='linear')(x)\n",
        "\n",
        "# Define the Cold Start Model\n",
        "cold_start_model = Model(inputs=[book_input, context_input], outputs=output)\n",
        "cold_start_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Model Summary\n",
        "print(cold_start_model.summary())\n",
        "\n",
        "# Train the Model\n",
        "history_cold_start = cold_start_model.fit(\n",
        "    [book_train, X_train], y_train,  # Using only training data\n",
        "    epochs=5,  # Increased for better learning\n",
        "    batch_size=64,  # Adjusted for small dataset\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "AGZMaT5HESNv",
        "outputId": "f4f524f4-51d8-4cc1-b756-5ffa67ead3e1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (30000, 1528)\n",
            "book_train shape: (30000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ book_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ book_embedding            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │        \u001b[38;5;34m665,500\u001b[0m │ book_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ book_flatten (\u001b[38;5;33mFlatten\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ book_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ context_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1528\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1578\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ book_flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ context_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m808,448\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ book_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ book_embedding            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">665,500</span> │ book_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ book_flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ book_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ context_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1528</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1578</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ book_flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ context_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">808,448</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,638,301\u001b[0m (6.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,638,301</span> (6.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,638,301\u001b[0m (6.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,638,301</span> (6.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/5\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 2.1288 - mae: 1.1360 - val_loss: 3.2205 - val_mae: 1.6084\n",
            "Epoch 2/5\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5562 - mae: 0.9707 - val_loss: 2.1505 - val_mae: 1.2550\n",
            "Epoch 3/5\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3052 - mae: 0.8679 - val_loss: 2.7505 - val_mae: 1.4535\n",
            "Epoch 4/5\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1539 - mae: 0.8126 - val_loss: 2.6044 - val_mae: 1.4020\n",
            "Epoch 5/5\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0865 - mae: 0.7831 - val_loss: 2.9221 - val_mae: 1.5006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the path to save the converted TFLite model\n",
        "tflite_model_path = \"cold_start_model.tflite\"\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(cold_start_model)\n",
        "\n",
        "# Apply optimization (quantization for smaller size and faster inference)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "with open(tflite_model_path, \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(f\"✅ Model successfully converted and saved as {tflite_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooz_oYqLEzrH",
        "outputId": "5471d9c6-ed6f-4e2c-d1b3-eeaadaec6b26"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpgillfpv8'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 1), dtype=tf.float32, name='book_input'), TensorSpec(shape=(None, 1528), dtype=tf.float32, name='context_input')]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138361776283408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138361776283600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138361776282448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138361776282832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138361776280528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138361776281296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138361776279376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138361776279952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138361776278608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "✅ Model successfully converted and saved as cold_start_model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the TFLite model (corrected file path)\n",
        "interpreter = tf.lite.Interpreter(model_path=\"cold_start_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input & output tensor details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Print expected input shapes for debugging\n",
        "print(f\"🔍 Expected Input 0 Shape: {input_details[0]['shape']}, Type: {input_details[0]['dtype']} (Context Features)\")\n",
        "print(f\"🔍 Expected Input 1 Shape: {input_details[1]['shape']}, Type: {input_details[1]['dtype']} (Book ID)\")\n",
        "\n",
        "# Function to run inference with TFLite model\n",
        "def predict_tflite(context_feature, book_id):\n",
        "    \"\"\"Runs inference using the TensorFlow Lite model with correctly shaped inputs.\"\"\"\n",
        "    # Convert inputs to FLOAT32 and match expected shapes\n",
        "    context_feature = np.array(context_feature, dtype=np.float32).reshape(1, -1)  # Ensure (1, feature_dim)\n",
        "    book_id = np.array(book_id, dtype=np.float32).reshape(1, 1)  # Ensure (1, 1)\n",
        "\n",
        "    # Ensure input shapes match model expectations\n",
        "    assert context_feature.shape == tuple(input_details[0]['shape']), f\"Mismatch in context_feature shape: {context_feature.shape}\"\n",
        "    assert book_id.shape == tuple(input_details[1]['shape']), f\"Mismatch in book_id shape: {book_id.shape}\"\n",
        "\n",
        "    # Set model inputs (Swapped order to match TFLite expectations)\n",
        "    interpreter.set_tensor(input_details[0]['index'], context_feature)\n",
        "    interpreter.set_tensor(input_details[1]['index'], book_id)\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get output prediction\n",
        "    return interpreter.get_tensor(output_details[0]['index'])[0][0]  # Return scalar prediction\n",
        "\n",
        "# Test the model with a sample (use 10 test samples)\n",
        "sample_context_features = X_test[:10]  # Context features (feature_dim per book)\n",
        "sample_book_ids = book_test[:10].reshape(-1, 1)  # Encoded book IDs\n",
        "\n",
        "# Get TFLite model predictions for each sample (one-by-one)\n",
        "tflite_predictions = [predict_tflite(context_feature, book_id)\n",
        "                      for context_feature, book_id in zip(sample_context_features, sample_book_ids)]\n",
        "\n",
        "# Convert to NumPy array\n",
        "tflite_predictions = np.array(tflite_predictions)\n",
        "\n",
        "print(\"✅ TFLite Model Inference Completed. Sample Predictions:\", tflite_predictions[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlqnQTd-E0bj",
        "outputId": "8b36d272-5f21-45e5-9960-62a88ef1f1d4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Expected Input 0 Shape: [   1 1528], Type: <class 'numpy.float32'> (Context Features)\n",
            "🔍 Expected Input 1 Shape: [1 1], Type: <class 'numpy.float32'> (Book ID)\n",
            "✅ TFLite Model Inference Completed. Sample Predictions: [2.1873565 2.6881132 2.2176178 3.4464824 2.1201553]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Get true ratings for the same test samples used for inference\n",
        "y_true = y_test[:10]\n",
        "\n",
        "# Compute RMSE for TFLite model predictions\n",
        "rmse = np.sqrt(mean_squared_error(y_true, tflite_predictions))\n",
        "\n",
        "# Function to compute Precision@K\n",
        "def precision_at_k(y_true, y_pred, k=5):\n",
        "    \"\"\"Computes Precision@K for Top-K recommendations.\"\"\"\n",
        "    top_k_preds = np.argsort(y_pred)[::-1][:k]  # Get top-K predicted indices\n",
        "    relevant_items = set(np.argsort(y_true)[::-1][:k])  # Get top-K actual relevant indices\n",
        "    return len(set(top_k_preds) & relevant_items) / k\n",
        "\n",
        "# Function to compute Recall@K\n",
        "def recall_at_k(y_true, y_pred, k=5):\n",
        "    \"\"\"Computes Recall@K for Top-K recommendations.\"\"\"\n",
        "    top_k_preds = np.argsort(y_pred)[::-1][:k]  # Get top-K predicted indices\n",
        "    relevant_items = set(np.argsort(y_true)[::-1][:k])  # Get top-K actual relevant indices\n",
        "    return len(set(top_k_preds) & relevant_items) / len(relevant_items)\n",
        "\n",
        "# Compute Precision@K and Recall@K\n",
        "k = 5\n",
        "precision_k = precision_at_k(y_true, tflite_predictions, k)\n",
        "recall_k = recall_at_k(y_true, tflite_predictions, k)\n",
        "\n",
        "# Display results\n",
        "rmse, precision_k, recall_k\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KroBwD2rFS8f",
        "outputId": "cd641592-edfd-47a1-eef0-04f3cb675c5a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.5690924616423927, 0.6, 0.6)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure we have the correct test set for the cold_start_model\n",
        "num_samples = min(10, len(y_test))\n",
        "\n",
        "# Predict using the cold_start_model (original Keras model before compression)\n",
        "cold_start_predictions = cold_start_model.predict([book_test[:num_samples], X_test[:num_samples]]).flatten()\n",
        "\n",
        "# Compute RMSE for cold_start_model\n",
        "rmse_cold_start = np.sqrt(mean_squared_error(y_test[:num_samples], cold_start_predictions))\n",
        "\n",
        "# Convert True Ratings to Binary Relevance (ratings >= 4.0 are relevant)\n",
        "y_true_binary_cold_start = (y_test[:num_samples] >= 4.0).astype(int)\n",
        "\n",
        "# Compute Precision@10 and Recall@10 for cold_start_model\n",
        "k = 10\n",
        "precision_k_cold_start = precision_at_k(y_true_binary_cold_start, cold_start_predictions, k)\n",
        "recall_k_cold_start = recall_at_k(y_true_binary_cold_start, cold_start_predictions, k)\n",
        "\n",
        "# Display results\n",
        "rmse_cold_start, precision_k_cold_start, recall_k_cold_start\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7AqCl_1LRVc",
        "outputId": "b380933c-166c-48f2-cc9e-e5826aed7566"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.5631697935742908, 1.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Compressed model size\\n\" , os.stat(\"cold_start_model.tflite\").st_size / (1024 * 1024))\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Save the original model as an H5 file\n",
        "original_model_path = \"cold_start_model.h5\"\n",
        "cold_start_model.save(original_model_path)\n",
        "\n",
        "print(f\" Original model saved as {original_model_path}\")\n",
        "print(os.stat(\"cold_start_model.h5\").st_size / (1024 * 1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EYPJRUDFE2x",
        "outputId": "290cec53-c2f0-4a4f-c2d0-0e151b31f0c2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compressed model size\n",
            " 1.579742431640625\n",
            " Original model saved as cold_start_model.h5\n",
            "18.793838500976562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Encode user IDs\n",
        "user_encoder = LabelEncoder()\n",
        "merged_df['user_id_encoded'] = user_encoder.fit_transform(merged_df['user_id'].astype(str))\n",
        "\n",
        "# Define target variable (already scaled)\n",
        "y_scaled = merged_df['user_rating'].values\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, user_train, user_test = train_test_split(\n",
        "    X, y_scaled, merged_df['user_id_encoded'].values, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "# Check data shapes\n",
        "print(\"✅ X_train shape:\", X_train.shape)\n",
        "print(\"✅ user_train shape:\", user_train.shape)\n",
        "\n",
        "# User Input and Embedding\n",
        "user_input = Input(shape=(1,), name='user_input')\n",
        "user_embedding = Embedding(input_dim=len(user_encoder.classes_), output_dim=50, name='user_embedding')(user_input)\n",
        "user_vec = Flatten(name='user_flatten')(user_embedding)\n",
        "\n",
        "# Movie Context Input\n",
        "movie_context_input = Input(shape=(X_train.shape[1],), name='movie_context_input')\n",
        "\n",
        "# Concatenate user embedding with movie context\n",
        "concat_user_movie = Concatenate()([user_vec, movie_context_input])\n",
        "\n",
        "# Dense Layers\n",
        "x = Dense(512, activation='relu')(concat_user_movie)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "output = Dense(1, activation='linear')(x)\n",
        "\n",
        "# Define Top-N User Recommendation Model\n",
        "top_n_user_model = Model(inputs=[user_input, movie_context_input], outputs=output)\n",
        "top_n_user_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Model summary\n",
        "print(top_n_user_model.summary())\n",
        "\n",
        "# Train the model with validation\n",
        "history = top_n_user_model.fit(\n",
        "    [user_train, X_train], y_train,\n",
        "    epochs=5,  # Increased for better learning\n",
        "    batch_size=64,  # Adjusted for dataset size\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "lwTZepjKG_nB",
        "outputId": "5b5f9683-3bae-42e4-c062-adf9a3ca0177"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ X_train shape: (30000, 1528)\n",
            "✅ user_train shape: (30000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ user_embedding            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │         \u001b[38;5;34m99,300\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ user_flatten (\u001b[38;5;33mFlatten\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ movie_context_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1528\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1578\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ user_flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ movie_context_input[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m808,448\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ user_embedding            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">99,300</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ user_flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ movie_context_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1528</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1578</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ movie_context_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">808,448</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,072,101\u001b[0m (4.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,072,101</span> (4.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,072,101\u001b[0m (4.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,072,101</span> (4.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/5\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 2.1861 - mae: 1.1322 - val_loss: 1.6889 - val_mae: 1.0949\n",
            "Epoch 2/5\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3929 - mae: 0.9180 - val_loss: 2.2251 - val_mae: 1.2995\n",
            "Epoch 3/5\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3353 - mae: 0.8923 - val_loss: 2.4716 - val_mae: 1.3820\n",
            "Epoch 4/5\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3108 - mae: 0.8829 - val_loss: 2.1790 - val_mae: 1.2799\n",
            "Epoch 5/5\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2740 - mae: 0.8624 - val_loss: 2.5435 - val_mae: 1.4024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# ✅ Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"top_n_user_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# ✅ Get input & output tensor details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# ✅ Print expected input shapes for debugging\n",
        "print(f\"🔍 Expected User Input Shape: {input_details[0]['shape']}, Type: {input_details[0]['dtype']}\")\n",
        "print(f\"🔍 Expected Movie Context Input Shape: {input_details[1]['shape']}, Type: {input_details[1]['dtype']}\")\n",
        "\n",
        "# ✅ Check the actual shape of movie context features (X_test)\n",
        "print(f\"🔍 Actual Feature Shape: {X_test.shape}\")  # Check actual feature size\n",
        "\n",
        "# ✅ Fix feature shape if necessary\n",
        "expected_feature_dim = input_details[0]['shape'][1]  # Get expected feature size from model\n",
        "if X_test.shape[1] != expected_feature_dim:\n",
        "    raise ValueError(f\"❌ Shape mismatch: Model expects {expected_feature_dim} features, but got {X_test.shape[1]}\")\n",
        "\n",
        "# ✅ Function to run inference with TFLite model\n",
        "def predict_tflite(user_id, movie_context):\n",
        "    \"\"\"Runs inference using the TensorFlow Lite model with correctly shaped inputs.\"\"\"\n",
        "    # Convert inputs to FLOAT32 and reshape to expected dimensions\n",
        "    movie_context = np.array(movie_context, dtype=np.float32).reshape(1, expected_feature_dim)  # Ensure correct shape\n",
        "    user_id = np.array(user_id, dtype=np.float32).reshape(1, 1)  # Ensure (1, 1)\n",
        "\n",
        "    # Set inputs to the interpreter\n",
        "    interpreter.set_tensor(input_details[0]['index'], movie_context)\n",
        "    interpreter.set_tensor(input_details[1]['index'], user_id)\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get output prediction\n",
        "    return interpreter.get_tensor(output_details[0]['index'])[0][0]  # Return scalar prediction\n",
        "\n",
        "# ✅ Run inference on test samples\n",
        "num_samples = 10\n",
        "movie_context_samples = X_test[:num_samples]  # Movie context features\n",
        "user_samples = user_test[:num_samples].reshape(-1, 1)  # User IDs\n",
        "\n",
        "# ✅ Run predictions\n",
        "tflite_predictions = np.array([\n",
        "    predict_tflite(user_id, movie_context)\n",
        "    for user_id, movie_context in zip(user_samples, movie_context_samples)\n",
        "])\n",
        "\n",
        "print(\"✅ TFLite Model Inference Completed. Sample Predictions:\", tflite_predictions[:5])\n",
        "\n",
        "# ✅ Compute RMSE\n",
        "y_true = y_test[:num_samples]\n",
        "rmse = np.sqrt(mean_squared_error(y_true, tflite_predictions))\n",
        "print(f\"📊 RMSE (TFLite Model): {rmse:.4f}\")\n",
        "\n",
        "# ✅ Precision@K and Recall@K Functions\n",
        "def precision_at_k(y_true, y_pred, k=5):\n",
        "    \"\"\"Computes Precision@K for Top-K recommendations.\"\"\"\n",
        "    top_k_preds = np.argsort(y_pred)[::-1][:k]\n",
        "    relevant_items = set(np.argsort(y_true)[::-1][:k])\n",
        "    return len(set(top_k_preds) & relevant_items) / k\n",
        "\n",
        "def recall_at_k(y_true, y_pred, k=5):\n",
        "    \"\"\"Computes Recall@K for Top-K recommendations.\"\"\"\n",
        "    top_k_preds = np.argsort(y_pred)[::-1][:k]\n",
        "    relevant_items = set(np.argsort(y_true)[::-1][:k])\n",
        "    return len(set(top_k_preds) & relevant_items) / len(relevant_items)\n",
        "\n",
        "# ✅ Compute Precision@K and Recall@K\n",
        "k = 5\n",
        "precision_k = precision_at_k(y_true, tflite_predictions, k)\n",
        "recall_k = recall_at_k(y_true, tflite_predictions, k)\n",
        "\n",
        "print(f\"📊 Precision@{k}: {precision_k:.4f}\")\n",
        "print(f\"📊 Recall@{k}: {recall_k:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3sOQ7uTGeS3",
        "outputId": "5d978e3d-0567-4d9b-87a7-fb4bb9730a95"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Expected User Input Shape: [   1 1528], Type: <class 'numpy.float32'>\n",
            "🔍 Expected Movie Context Input Shape: [1 1], Type: <class 'numpy.float32'>\n",
            "🔍 Actual Feature Shape: (10000, 1528)\n",
            "✅ TFLite Model Inference Completed. Sample Predictions: [2.0172863 3.1474802 2.9622478 2.3944912 2.844131 ]\n",
            "📊 RMSE (TFLite Model): 1.4740\n",
            "📊 Precision@5: 0.8000\n",
            "📊 Recall@5: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Function to Calculate RMSE\n",
        "def calculate_rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# Function to Calculate Precision@K\n",
        "def precision_at_k(y_true, y_pred, k):\n",
        "    \"\"\"Calculate Precision@K\"\"\"\n",
        "    top_k_indices = np.argsort(y_pred)[-k:][::-1]  # Get top-K predicted indices\n",
        "    relevant_indices = np.argsort(y_true)[-k:][::-1]  # Get top-K actual relevant indices\n",
        "    relevant = len(set(top_k_indices) & set(relevant_indices))  # Intersection count\n",
        "    return relevant / k\n",
        "\n",
        "# Function to Calculate Recall@K\n",
        "def recall_at_k(y_true, y_pred, k):\n",
        "    \"\"\"Calculate Recall@K\"\"\"\n",
        "    top_k_indices = np.argsort(y_pred)[-k:][::-1]  # Get top-K predicted indices\n",
        "    total_relevant = np.sum(y_true)  # Total number of relevant items\n",
        "    if total_relevant == 0:\n",
        "        return 0.0  # Avoid division by zero\n",
        "    relevant = np.isin(top_k_indices, np.where(y_true == 1)[0]).sum()  # Count hits\n",
        "    return relevant / total_relevant\n",
        "\n",
        "# ✅ Predict on the Test Set\n",
        "predictions = top_n_user_model.predict([user_test, X_test]).flatten()\n",
        "\n",
        "# ✅ Calculate RMSE\n",
        "rmse_score = calculate_rmse(y_test, predictions)\n",
        "print(f\"📊 RMSE: {rmse_score:.4f}\")\n",
        "\n",
        "# ✅ Convert True Ratings to Binary Relevance (ratings >= 4.0 are relevant)\n",
        "y_true_binary = (y_test >= 4.0).astype(int)  # Fixed threshold\n",
        "\n",
        "# ✅ Calculate Precision@K and Recall@K for K=10\n",
        "k = min(10, len(y_true_binary))  # Adjust if fewer samples are present\n",
        "precision = precision_at_k(y_true_binary, predictions, k)\n",
        "recall = recall_at_k(y_true_binary, predictions, k)\n",
        "\n",
        "# ✅ Print Evaluation Metrics\n",
        "print(f\"📊 Precision@{k}: {precision:.4f}\")\n",
        "print(f\"📊 Recall@{k}: {recall:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44oL05nMIoCn",
        "outputId": "c8d0d6c6-fa3c-4a94-9acc-17dc1f42d11a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "📊 RMSE: 1.5851\n",
            "📊 Precision@10: 0.0000\n",
            "📊 Recall@10: 0.0015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwaGw9NeIoLz"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}